{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "from langchain.document_loaders import PyPDFLoader                 # PDF ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¡œë”\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # ë¬¸ì„œë¥¼ ì¼ì • ë‹¨ìœ„ë¡œ ìª¼ê°œëŠ” ë„êµ¬\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings          # OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©\n",
    "from langchain.vectorstores import Chroma                          # ë²¡í„° DBì¸ Chroma ì‚¬ìš©\n",
    "from langchain_community.llms import Ollama                        # OpenAI GPT ëª¨ë¸ ì„¤ì •\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PDF íŒŒì¼ ë¡œë”© ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¬¸ì„œë¡œ ë¡œë“œ\n",
    "loader1 = PyPDFLoader(\"../data/squat1.pdf\")  # ë§Œì•½ íŒŒì¼ì˜ ì´ë¯¸ì§€ê¹Œì§€ ë¶ˆëŸ¬ì˜¤ê³  ì‹¶ë‹¤ë©´ extract_images=True ì¶”ê°€\n",
    "doc1 = loader1.load()\n",
    "\n",
    "loader2 = PyPDFLoader(\"../data/squat2.pdf\")\n",
    "doc2 = loader2.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ë¬¸ì„œ ì¡°ê°í™” (Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ë¶„í•  í´ë˜ìŠ¤ ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "split_docs = text_splitter.split_documents(doc1 + doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë° ChromaDBì— ì„ë² ë”© ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6712\\396006598.py:2: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6712\\396006598.py:2: LangChainDeprecationWarning: Default values for HuggingFaceBgeEmbeddings.model_name were deprecated in LangChain 0.2.5 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceBgeEmbeddings constructor instead.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6712\\396006598.py:11: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Embeddings()\n",
    "embedding_model = HuggingFaceBgeEmbeddings()\n",
    "\n",
    "# Chroma ë²¡í„° ì €ì¥ì†Œì— ë¬¸ì„œ ì„ë² ë”© ì €ì¥\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"../chroma_db/pdf_docs\")\n",
    "\n",
    "# ë¡œì»¬ì— ì €ì¥\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. retirever ê²€ìƒ‰ê¸° ì„¤ì • ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6712\\1071343833.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ Chroma ë²¡í„° DB ë¡œë“œ\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"../chroma_db/pdf_docs\",\n",
    "    embedding_function=embedding_model\n",
    "    )\n",
    "\n",
    "# Retriever ìƒì„±\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",           # ìœ ì‚¬ë„ ë¶„ì„ ê¸°ë°˜\n",
    "    search_kwargs={\"k\": 5}              # 3ê°œì˜ ë¬¸ì¥ë§Œ ê°–ê³ ì˜¤ê¸°\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. LLM ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local LLM Model (Ollama: llama3)\n",
    "llm = Ollama(model=\"llama3\", temperature=0)          # temperature: ì°½ì˜ì„± ë ˆë²¨ (0~1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. RAG Chain ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "rag_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    # chain_type=\"stuff\",                 # stuff: ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë‹¨ìˆœíˆ ì´ì–´ë¶™ì—¬ì„œ LLMì— ì „ë‹¬í•˜ëŠ” ë°©ì‹\n",
    "    # chain_type=\"map_reduce\",            # map_reduce: ê° ë¬¸ì„œë¥¼ ê°œë³„ì ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ë§ˆì§€ë§‰ì— LLMì´ ì¢…í•©í•´ì„œ ë‹µë³€ ìƒì„±í•˜ëŠ” ë°©ì‹\n",
    "    # retriever=retriever,\n",
    "    verbose=True      # ì°¸ì¡° ë¬¸ì„œë¥¼ ê²°ê³¼ì— í¬í•¨\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Query Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: ìŠ¤ì¿¼íŠ¸í•  ë•Œ ì²™ì¶” ì¤‘ë¦½ì„ ìœ ì§€í•´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ì•Œë ¤ì¤˜\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ğŸ“˜ Llama3 ì‘ë‹µ:\n",
      "A great question! ğŸ˜Š\n",
      "\n",
      "When performing squats, maintaining a neutral spine position is crucial for several reasons. Firstly, when the spine is in a neutral position, it allows for optimal activation of the gluteal muscles, which are responsible for hip extension and external rotation during the squat movement. This ensures proper engagement of the glutes, reducing the risk of overusing or underusing them.\n",
      "\n",
      "Secondly, a neutral spine helps to maintain proper pelvic alignment, which is essential for maintaining good posture and preventing excessive strain on the lower back. When the pelvis is in a neutral position, it allows for even distribution of weight-bearing forces across the entire pelvis, rather than concentrating them at the front or back, which can lead to discomfort or injury.\n",
      "\n",
      "Thirdly, maintaining a neutral spine during squats helps to reduce the risk of lumbar flexion, which can put excessive stress on the intervertebral discs and facet joints in the lower back. This is particularly important for individuals with pre-existing spinal conditions, such as spondylolisthesis or spinal stenosis.\n",
      "\n",
      "Lastly, a neutral spine position during squats helps to promote proper activation of the core muscles, including the transverse abdominis and obliques, which are essential for maintaining good posture and stability throughout the movement.\n",
      "\n",
      "So, there you have it! Maintaining a neutral spine during squats is crucial for optimal gluteal activation, pelvic alignment, spinal health, and overall movement efficiency. ğŸ’ª\n"
     ]
    }
   ],
   "source": [
    "query = \"ìŠ¤ì¿¼íŠ¸í•  ë•Œ ì²™ì¶” ì¤‘ë¦½ì„ ìœ ì§€í•´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "# RAG ì²´ì¸ì— ì§ˆë¬¸ ì „ë‹¬\n",
    "response = rag_chain.predict(input=query)\n",
    "\n",
    "# ë‹µë³€ ì¶œë ¥\n",
    "print(\"ğŸ“˜ Llama3 ì‘ë‹µ:\")\n",
    "# print(response['result'])\n",
    "print(response)\n",
    "\n",
    "# ì°¸ì¡° ë¬¸ì„œ ì¶œë ¥ (ì„ íƒ)\n",
    "# print(\"\\nğŸ“„ ì°¸ì¡° ë¬¸ì„œ:\")\n",
    "# print(response['source_documents'][1].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "komi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
