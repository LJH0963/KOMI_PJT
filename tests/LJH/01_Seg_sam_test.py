import cv2
import numpy as np
import torch
import os
import glob
from ultralytics import YOLO
from segment_anything import sam_model_registry, SamPredictor

# ì…ë ¥ ë° ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
input_dir = "data/jeonsomi"  # ì…ë ¥ ì´ë¯¸ì§€ í´ë”
output_dir = "tests/LJH/output"  # ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì €ì¥ í´ë”
os.makedirs(output_dir, exist_ok=True)  # ì¶œë ¥ í´ë” ìƒì„±

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# YOLOv8 ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n.pt')

# SAM ëª¨ë¸ ë¡œë“œ
sam_checkpoint = "sam_vit_h_4b8939.pth"
model_type = "vit_h"
sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)
predictor = SamPredictor(sam)

# ì…ë ¥ í´ë” ë‚´ ëª¨ë“  jpg íŒŒì¼ ì°¾ê¸°
image_paths = glob.glob(os.path.join(input_dir, "*.jpg"))

# íŒŒì¼ì´ ì—†ì„ ê²½ìš° ê²½ê³ 
if not image_paths:
    print("âš  ê²½ê³ : í•´ë‹¹ ë””ë ‰í† ë¦¬ì— JPG íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")

# ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ë°˜ë³µ ì²˜ë¦¬
for image_path in image_paths:
    # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    image_name = os.path.basename(image_path).split(".")[0]  # í™•ì¥ì ì œê±°
    output_path = os.path.join(output_dir, f"{image_name}_mask.jpg")  # ì €ì¥ ê²½ë¡œ ì„¤ì •

    print(f"â–¶ ì²˜ë¦¬ ì¤‘: {image_path} â†’ {output_path}")

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ì˜¤ë¥˜: {image_path} ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        continue

    # ê°ì²´ ê²€ì¶œ ìˆ˜í–‰
    results = model.predict(source=image, conf=0.6)

    # ê²€ì¶œëœ ê²½ê³„ ìƒì ì¶”ì¶œ
    bboxes = results[0].boxes.xyxy.cpu().numpy()

    # ì´ë¯¸ì§€ RGBë¡œ ë³€í™˜
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # SAMì— ì´ë¯¸ì§€ ì„¤ì •
    predictor.set_image(image_rgb)

    # ê²½ê³„ ìƒìë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ìƒì„±
    transformed_boxes = predictor.transform.apply_boxes_torch(torch.tensor(bboxes, dtype=torch.float32), image_rgb.shape[:2])
    masks, _, _ = predictor.predict_torch(
        point_coords=None,
        point_labels=None,
        boxes=transformed_boxes.to(device),
        multimask_output=False
    )

    # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¹ˆ ë§ˆìŠ¤í¬ ìƒì„± (í°ìƒ‰ ë°°ê²½)
    segmentation_result = np.ones_like(image_rgb[:, :, 0]) * 255  # í°ìƒ‰ (255)

    # ë§ˆìŠ¤í¬ ì ìš© (ê°ì²´ ë¶€ë¶„ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ë³€ê²½)
    for mask in masks:
        mask = mask.cpu().numpy().astype(np.uint8).squeeze()  # ì°¨ì› ì¶•ì†Œ í›„ ì ìš©
        segmentation_result[mask > 0] = 0  # ê°ì²´ ë¶€ë¶„ì„ ê²€ì€ìƒ‰(0)ìœ¼ë¡œ ì„¤ì •

    # ê²°ê³¼ ì €ì¥
    cv2.imwrite(output_path, segmentation_result)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")

print("ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!")
